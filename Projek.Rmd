---
title: "Proyek Akhir"
author: "Anggit Pambudi Hutomo"
date: "25/12/2021"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
setwd(dirname(rstudioapi::getSourceEditorContext()$path)) # auto set directory

# library(readr)
library(tm) # pre-prosessing data
library(corpus) # fungsi corpus
library(tidymodels)
library(stringr)
library(dplyr) # Data wrangling & manipulation
library(tidytext) # For unnest_tokens
library(ggplot2) # For data visualizations & graphs

# wordcloud
library(wordcloud)
library(RColorBrewer)

# library shiny
library(shiny)

```

```{r}
df <- read.csv("Corona_NLP_train.csv")

df
```

```{r}
#Grouping Sentiment Column
p1 <- df %>%
  group_by(Sentiment) %>% 
  tally() %>% 
  ggplot(aes(x=Sentiment, y=n, fill = Sentiment)) +
  theme(axis.text.x = element_text(angle = 45, 
                                   size=14,
                                   color = "black")) +
  geom_col() +
  geom_text(
    aes(label = n), 
    colour = "black", 
    fontface = "bold",
    position=position_dodge(width=0.9), 
    vjust=-0.25)
p1
```


```{r}
#Data Cleansing
df$TweetAt <- sub("-", "/", df$TweetAt)
df$TweetAt <- sub("-", "/", df$TweetAt)
df$TweetAt <- as.Date(df$TweetAt , format = "%d/%m/%y")
df = na.omit(df)
```

```{r}
#Memunculkan data tweet perhari
p2 <-df %>%
  group_by(TweetAt) %>% 
  tally() %>%
  ggplot(aes(x=TweetAt, y=n)) +
  theme(axis.text.x = element_text(angle = 90)) +
  scale_x_date(breaks = df$TweetAt) + 
  geom_col()
p2
```

```{r}
#menghilangkan karakter seperti @ https dan lain2
df$Tweets <- sapply(strsplit(as.character(df$OriginalTweet),split=' '),function(s) paste(s[!grepl('^@',s)],collapse=' ')) 

df$Tweets <- sapply(strsplit(as.character(df$Tweets),split=' '),function(s) paste(s[!grepl('^https:',s)],collapse=' '))


df$Tweets <- gsub("(?:\\s+|^)\\S*(?<!\\w)(?:@?|<filter>)(?!\\w)\\S*", "", df$Tweets, perl=TRUE)
```

```{r}
#Tweet berdasarkan Lokasi
text <- c(df$Location)
text <- paste(text, collapse = " ")
text <- str_replace_all(text, pattern = '\"', replacement = "") # Remove slashes
text <- str_replace_all(text, pattern = '\n', replacement = "") # Remove \n
text <- str_replace_all(text, pattern = '\u0092', replacement = "'") #Replace with quote
text <- str_replace_all(text, pattern = '\u0091', replacement = "'") #Replace with quote

text_df <- data_frame(Text = text) # tibble aka neater data frame
text_words <- text_df %>% 
  unnest_tokens(output = word, input = Text) #tokenisasi

# data(stop_words) # Stop words.
text_words  <- text_words  %>%
  anti_join(stop_words) # Remove stop words in peter_words

# Word Counts:
text_wordcounts <- text_words  %>% count(word, sort = TRUE)
p3 <- text_wordcounts %>% 
  arrange(desc(n)) %>% 
  head(6) %>% 
  ggplot(aes(x=n,y=word))+
  geom_col() + ylab("Location") +
  theme(axis.text = element_text(size=12,
                                 color = "black"),
        legend.text = element_text(size=12))

head(text_wordcounts)
p3
```

```{r}
#WordCloud
docs <- Corpus(VectorSource(df$Tweets))

# pre-processing
docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>% #Menghilang koma dll.
  tm_map(stripWhitespace) %>%
  tm_map(stemDocument) # menghilangkan kata mirip
docs <- tm_map(docs, content_transformer(tolower))

# menghilangkan konjungsi
docs <- tm_map(docs, removeWords, stopwords("english"))

# set.seed(1234) # for reproducibility 
wordcloud1 <- wordcloud(docs
                       , max.words=500    # Set top n words
                       , random.order=FALSE # Words in decreasing freq
                       , rot.per=0.35       # % of vertical words
                       , use.r.layout=FALSE # Use C++ collision detection
                       , colors=brewer.pal(1, "Dark2"))
```

```{r}
words <- df$Tweets

words <- data_frame(Text = words)
# head(words, n = 20)
words <- words %>%
  # tm_map(removePunctuation) %>%
  unnest_tokens(output = word, input = Text)%>%
  anti_join(stop_words) %>% # Remove stop words in peter_words
  count(word, sort = TRUE)

words = na.omit(words) #hapus baris yang kososng


# words <- gsub("[0-9]+", "", words$word) 
```

```{r}
#Plot Top Word
p4 <- words %>% 
  filter(n > 2000) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n)) + 
  geom_col() +
  coord_flip() +
  labs(x = "Word \n", y = "\n Count ", title = "Frequent Words\n") +
  geom_text(aes(label = n), hjust = 1.2, colour = "white", fontface = "bold") +
  theme(plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(face="bold", colour="darkblue", size = 12),
        axis.title.y = element_text(face="bold", colour="darkblue", size = 12))
p4
```

```{r}
ui <- shinyUI(
  navbarPage("Analisis Sentimen",
             tabPanel("Tabel",
                      mainPanel(
                        h2("Tabel Data Tweets Covid-19", align = "center"),
                        dataTableOutput('table'),width = "100%"
                      )
             ),
             tabPanel("Sentiment",
                      mainPanel(
                        h2("Jumlah Tiap Sentiment", align = "center"),
                        plotOutput(outputId = "plot1"),width = "100%")
             ),
             tabPanel("Tweets Covid-19 Perhari",
                      mainPanel(
                        h2("Jumlah Tweets dalam Satu Hari", align = "center"),
                        plotOutput(outputId = "plot2"),width = "100%")
             ),
             tabPanel("Lokasi",
                      mainPanel(
                        h2("Jumlah Tweets Berdasarkan Lokasi", 
                           align = "center"),
                        plotOutput(outputId = "plot3"),width = "100%")
             ),
             tabPanel("Jumlah Kata",
                      mainPanel(
                        h2("Jumlah Kata Pada Tweets", 
                           align = "center"),
                        plotOutput(outputId = "plot4"),width = "100%")
             ),
             tabPanel("Word Cloud",
                      mainPanel(
                        h2("WordCloud Covid-19 Tweets", 
                           align = "center"),
                        plotOutput(outputId = "wordcloud"),width = "100%")
             )
  )
)

server <- function(input, output) {
  output$table <-renderDataTable(df) # tabel tweets
  output$plot1 <-renderPlot({ # plotsentimen
    plot(p1)
  })
  output$plot2 <-renderPlot({ # plot tweets  harian
    plot(p2)
  })
  output$plot3 <-renderPlot({ # plot lokasi tweets
    plot(p3)
  })
  output$plot4 <-renderPlot({ # plot jumlah kata
    plot(p4)
  })
  output$wordcloud <-renderPlot({  # plot word cloud
    wordcloud(docs
                       , max.words=500    # Set top n words
                       , random.order=FALSE # Words in decreasing freq
                       , rot.per=0.35       # % of vertical words
                       , use.r.layout=FALSE # Use C++ collision detection
                       , colors=brewer.pal(1, "Dark2"))
  })
}

```

```{r}
shinyApp(ui, server) #tampilkan dalam shiny
```